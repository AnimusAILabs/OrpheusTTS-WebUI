<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Streaming Audio Playback</title>
</head>
<body>
  <h1>Streaming Audio Playback</h1>
  <form id="promptForm">
    <label for="promptInput">Enter Prompt:</label><br>
    <textarea id="promptInput" rows="4" cols="50" placeholder="Type your prompt here" required></textarea><br>
    <button type="submit">Generate Audio</button>
  </form>
  <div id="status"></div>
  <script>
    // AudioWorklet processor code as a string
    const workletCode = `
      class AudioChunkProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          this.buffers = [];           // Array to store incoming chunks in order
          this.currentBuffer = null;    // Current buffer being played
          this.currentPosition = 0;     // Position in current buffer
          this.minBufferSize = 9600;   // 0.4 seconds at 24kHz
          this.maxBufferSize = 48000;  // 2 seconds at 24kHz
          this.totalBuffered = 0;      // Total samples buffered
          this.isPlaying = false;
          
          this.port.onmessage = (e) => {
            // Add new data to our buffers array
            this.buffers.push(new Float32Array(e.data));
            this.totalBuffered += e.data.length;

            // Start playback if we have enough data buffered
            if (!this.isPlaying && this.totalBuffered >= this.minBufferSize) {
              this.isPlaying = true;
              console.log('Starting playback with buffer size:', this.totalBuffered);
            }

            // Clean up if we're buffering too much
            while (this.totalBuffered > this.maxBufferSize && this.buffers.length > 1) {
              const removed = this.buffers.shift();
              this.totalBuffered -= removed.length;
            }
          };
        }

        process(inputs, outputs, parameters) {
          const output = outputs[0][0];
          
          // Don't output anything until we have enough data buffered
          if (!this.isPlaying) {
            output.fill(0);
            return true;
          }

          // If we're running low on data, pause playback
          if (this.totalBuffered < this.minBufferSize) {
            this.isPlaying = false;
            output.fill(0);
            return true;
          }

          // Fill the output buffer
          for (let i = 0; i < output.length; i++) {
            // If we need a new buffer
            if (!this.currentBuffer || this.currentPosition >= this.currentBuffer.length) {
              // Get next buffer if available
              if (this.buffers.length > 0) {
                this.currentBuffer = this.buffers.shift();
                this.currentPosition = 0;
                this.totalBuffered -= this.currentBuffer.length;
              } else {
                // No more buffers available
                output[i] = 0;
                continue;
              }
            }

            // Copy from current buffer
            output[i] = this.currentBuffer[this.currentPosition++];
          }

          return true;
        }
      }

      registerProcessor('audio-chunk-processor', AudioChunkProcessor);
    `;

    // Create a Blob containing the AudioWorklet code
    const workletBlob = new Blob([workletCode], { type: 'application/javascript' });
    const workletUrl = URL.createObjectURL(workletBlob);

    // Dynamically construct WebSocket URL
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const wsUrl = `${protocol}//${window.location.host}/ws`;
    const ws = new WebSocket(wsUrl);
    let audioContext = null;
    let workletNode = null;
    let isFirstChunk = true;
    let audioInitialized = false;

    function showStatus(message) {
      document.getElementById('status').textContent = message;
    }

    // Initialize Web Audio API and AudioWorklet
    async function initAudio() {
      if (!audioContext) {
        try {
          audioContext = new (window.AudioContext || window.webkitAudioContext)({sampleRate: 24000});
          await audioContext.audioWorklet.addModule(workletUrl);
          workletNode = new AudioWorkletNode(audioContext, 'audio-chunk-processor');
          workletNode.connect(audioContext.destination);
          audioInitialized = true;
          console.log('Audio system initialized successfully');
        } catch (error) {
          console.error('Failed to initialize audio:', error);
          showStatus('Failed to initialize audio system');
        }
      }
      return audioContext;
    }

    // Convert WAV chunk to Float32Array
    function processAudioChunk(chunk) {
      // Convert 16-bit PCM to float32
      const view = new DataView(chunk);
      const floatData = new Float32Array(chunk.byteLength / 2);
      for (let i = 0; i < floatData.length; i++) {
        const int16 = view.getInt16(i * 2, true);
        floatData[i] = int16 / 32768.0; // Convert to float32 (-1.0 to 1.0)
      }
      return floatData;
    }

    // WebSocket event handlers
    ws.onopen = () => {
      console.log('Connected to server');
      showStatus('Connected to server. Click Generate Audio to begin.');
    };

    ws.onclose = () => {
      console.log('Disconnected from server');
      showStatus('Disconnected from server');
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
      showStatus('WebSocket error occurred');
    };

    ws.onmessage = async (event) => {
      const data = JSON.parse(event.data);
      
      if (data.type === 'audio_chunk') {
        const chunk = new Uint8Array(hexToArrayBuffer(data.chunk));
        
        if (isFirstChunk) {
          isFirstChunk = false;
          // Skip processing the WAV header
          return;
        }

        if (!audioInitialized || !workletNode) {
          console.error('Audio system not initialized');
          return;
        }

        try {
          // Process chunk and send to AudioWorklet
          const floatData = processAudioChunk(chunk.buffer);
          workletNode.port.postMessage(floatData);
        } catch (error) {
          console.error('Error processing audio chunk:', error);
        }
        
      } else if (data.type === 'generation_complete') {
        console.log('Audio generation completed');
        showStatus('Audio streaming completed');
        isFirstChunk = true;
      }
    };

    // Convert hex string to ArrayBuffer
    function hexToArrayBuffer(hexString) {
      const bytes = new Uint8Array(hexString.length / 2);
      for (let i = 0; i < hexString.length; i += 2) {
        bytes[i / 2] = parseInt(hexString.substr(i, 2), 16);
      }
      return bytes.buffer;
    }

    // Form submission handler
    document.getElementById("promptForm").addEventListener("submit", async function(event) {
      event.preventDefault();
      
      if (!audioInitialized) {
        try {
          await initAudio();
        } catch (error) {
          console.error('Failed to initialize audio:', error);
          showStatus('Failed to initialize audio system');
          return;
        }
      }

      const prompt = document.getElementById("promptInput").value;
      showStatus('Generating audio...');
      isFirstChunk = true;
      
      // Request new audio generation
      ws.send(JSON.stringify({ prompt: prompt }));
    });
  </script>
</body>
</html>
